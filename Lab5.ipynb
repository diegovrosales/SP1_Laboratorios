{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Lab5.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMJNs1O3wX4a0JhRj9aYQel",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/diegovrosales/SP1_Laboratorios/blob/master/Lab5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J67iqZ_ri3kN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Embedding, Bidirectional, LSTM, Dropout, Conv1D, MaxPooling1D, GRU\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pylab as plt\n",
        "\n",
        "#dark mode\n",
        "plt.rc_context({'xtick.color':'w', 'ytick.color':'w', 'text.color':'w', 'axes.labelcolor':'w'})\n",
        "\n",
        "seed=1234\n",
        "np.random.seed(seed)\n",
        "tf.random.set_seed(seed)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ITSlX73dYPtU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 547
        },
        "outputId": "d3b59e54-376a-4368-d91d-fcb9b548340c"
      },
      "source": [
        "dataset, info = tfds.load('imdb_reviews/subwords8k', with_info=True, as_supervised=True)\n",
        "train_dataset, test_dataset = dataset['train'], dataset['test']\n",
        "info"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tfds.core.DatasetInfo(\n",
              "    name='imdb_reviews',\n",
              "    version=1.0.0,\n",
              "    description='Large Movie Review Dataset.\n",
              "This is a dataset for binary sentiment classification containing substantially more data than previous benchmark datasets. We provide a set of 25,000 highly polar movie reviews for training, and 25,000 for testing. There is additional unlabeled data for use as well.',\n",
              "    homepage='http://ai.stanford.edu/~amaas/data/sentiment/',\n",
              "    features=FeaturesDict({\n",
              "        'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=2),\n",
              "        'text': Text(shape=(None,), dtype=tf.int64, encoder=<SubwordTextEncoder vocab_size=8185>),\n",
              "    }),\n",
              "    total_num_examples=100000,\n",
              "    splits={\n",
              "        'test': 25000,\n",
              "        'train': 25000,\n",
              "        'unsupervised': 50000,\n",
              "    },\n",
              "    supervised_keys=('text', 'label'),\n",
              "    citation=\"\"\"@InProceedings{maas-EtAl:2011:ACL-HLT2011,\n",
              "      author    = {Maas, Andrew L.  and  Daly, Raymond E.  and  Pham, Peter T.  and  Huang, Dan  and  Ng, Andrew Y.  and  Potts, Christopher},\n",
              "      title     = {Learning Word Vectors for Sentiment Analysis},\n",
              "      booktitle = {Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies},\n",
              "      month     = {June},\n",
              "      year      = {2011},\n",
              "      address   = {Portland, Oregon, USA},\n",
              "      publisher = {Association for Computational Linguistics},\n",
              "      pages     = {142--150},\n",
              "      url       = {http://www.aclweb.org/anthology/P11-1015}\n",
              "    }\"\"\",\n",
              "    redistribution_info=,\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TfDAgU-VY8eZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "670e1bd8-ff97-40ab-8fd3-5126d16b1952"
      },
      "source": [
        "encoder = info.features['text'].encoder\n",
        "print ('Vocabulary size: {}'.format(encoder.vocab_size))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Vocabulary size: 8185\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "196FtYpZY_Ui",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "396a3dac-20fc-48c6-ff6d-75705c2e2e4e"
      },
      "source": [
        "sample_input = 'Hello, world!'\n",
        "encoded = encoder.encode(sample_input)\n",
        "decoded = encoder.decode(encoded)\n",
        "print(encoded, decoded, \"\\n\")\n",
        "\n",
        "for index in encoded:\n",
        "  print('{}\\t-> {}'.format(index, encoder.decode([index])))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[4025, 8040, 2, 562, 7962] Hello, world! \n",
            "\n",
            "4025\t-> Hell\n",
            "8040\t-> o\n",
            "2\t-> , \n",
            "562\t-> world\n",
            "7962\t-> !\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aULTZjlJZBhR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BATCH_SIZE = 64\n",
        "BUFFER_SIZE = 100000"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EE3_K_kLZEjr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "76271489-79f0-4c73-a6d8-19eb79e80eb8"
      },
      "source": [
        "train_shape = tuple(map(lambda x:x.shape,train_dataset.element_spec))\n",
        "test_shape = tuple(map(lambda x:x.shape,test_dataset.element_spec))\n",
        "train_shape, test_shape"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((TensorShape([None]), TensorShape([])),\n",
              " (TensorShape([None]), TensorShape([])))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DaYHC_i0ZGOj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "1dc9a3f4-e3ac-4f3a-efae-e27c904ac38a"
      },
      "source": [
        "train_dataset = train_dataset.shuffle(BUFFER_SIZE)\n",
        "train_dataset = train_dataset.padded_batch(BATCH_SIZE, train_shape)\n",
        "test_dataset = test_dataset.padded_batch(BATCH_SIZE,test_shape)\n",
        "\n",
        "train_dataset.element_spec"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TensorSpec(shape=(None, None), dtype=tf.int64, name=None),\n",
              " TensorSpec(shape=(None,), dtype=tf.int64, name=None))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xqssM37ZZIav",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "EPOCHS = 5\n",
        "STEPS_PER_EPOCH = 32\n",
        "VALIDATION_STEPS = 16"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b_LSnc28ZJ0J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(model, epochs=EPOCHS):\n",
        "  model.compile(loss='binary_crossentropy',\n",
        "                optimizer='adam',\n",
        "                metrics=['accuracy'])\n",
        "\n",
        "  return model.fit(train_dataset, epochs=epochs,\n",
        "                      steps_per_epoch=STEPS_PER_EPOCH,\n",
        "                      validation_data=test_dataset,\n",
        "                      validation_steps=VALIDATION_STEPS\n",
        "                      )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nniSG6ZwZLfJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_accuracy_and_loss(history):\n",
        "  acc = history.history['accuracy']\n",
        "  val_acc = history.history['val_accuracy']\n",
        "\n",
        "  loss = history.history['loss']\n",
        "  val_loss = history.history['val_loss']\n",
        "\n",
        "  plt.figure(figsize=(10, 10))\n",
        "  plt.subplot(2, 1, 1)\n",
        "  plt.plot(acc, label='Training Accuracy')\n",
        "  plt.plot(val_acc, label='Validation Accuracy')\n",
        "  plt.legend(loc='lower right')\n",
        "  plt.setp(plt.legend().get_texts(), color='black')\n",
        "  plt.ylabel('Accuracy')\n",
        "  plt.ylim([min(plt.ylim()),1.0])\n",
        "  plt.title('Training and Validation Accuracy')\n",
        "\n",
        "  plt.subplot(2, 1, 2)\n",
        "  plt.plot(loss, label='Training Loss')\n",
        "  plt.plot(val_loss, label='Validation Loss')\n",
        "  plt.legend(loc='upper right')\n",
        "  plt.setp(plt.legend().get_texts(), color='black')\n",
        "  plt.ylabel('Cross Entropy')\n",
        "  plt.ylim([0.0,1.0])\n",
        "  plt.title('Training and Validation Loss')\n",
        "  plt.xlabel('epoch')\n",
        "  plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "quFNIjtBZNp0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "6d2f04b1-ab93-48fa-e77a-22a5a26a1cf1"
      },
      "source": [
        "model = Sequential([\n",
        "    Embedding(encoder.vocab_size, 32, mask_zero=True),\n",
        "    Bidirectional(LSTM(64)),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, None, 32)          261920    \n",
            "_________________________________________________________________\n",
            "bidirectional_1 (Bidirection (None, 128)               49664     \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 129       \n",
            "=================================================================\n",
            "Total params: 311,713\n",
            "Trainable params: 311,713\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-IGyGjlFZQjS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "9e4ee731-54c6-475a-d502-eb977a706500"
      },
      "source": [
        "history = train(model)\n",
        "plot_accuracy_and_loss(history)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train for 32 steps, validate for 16 steps\n",
            "Epoch 1/5\n",
            "32/32 [==============================] - 150s 5s/step - loss: 0.6923 - accuracy: 0.5381 - val_loss: 0.6895 - val_accuracy: 0.5918\n",
            "Epoch 2/5\n",
            "32/32 [==============================] - 153s 5s/step - loss: 0.6639 - accuracy: 0.6265 - val_loss: 0.6200 - val_accuracy: 0.7100\n",
            "Epoch 3/5\n",
            "32/32 [==============================] - 142s 4s/step - loss: 0.5553 - accuracy: 0.7471 - val_loss: 0.5447 - val_accuracy: 0.7490\n",
            "Epoch 4/5\n",
            "32/32 [==============================] - 156s 5s/step - loss: 0.5057 - accuracy: 0.7886 - val_loss: 0.4966 - val_accuracy: 0.7959\n",
            "Epoch 5/5\n",
            "15/32 [=============>................] - ETA: 1:10 - loss: 0.4791 - accuracy: 0.8000"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "516_cgkzZSUl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Sequential([\n",
        "    Embedding(encoder.vocab_size, 32, mask_zero=True),\n",
        "    Bidirectional(LSTM(64,  return_sequences=True)),\n",
        "    Bidirectional(LSTM(32)),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}